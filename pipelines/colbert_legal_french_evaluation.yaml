# Legal RAG Evaluation Pipeline - ColBERT Legal French
#
# This pipeline queries a pre-built PLAID index with generated questions
# and evaluates retrieval quality using pyserini.
#
# Prerequisites:
#   Run colbert_legal_french_index.yaml first to build the index.
#
# Usage:
#   task-tracker submit pipelines/colbert_legal_french_evaluation.yaml

name: colbert_legal_french_evaluation
description: Batch query ColBERT Legal French index and evaluate retrieval
version: "2.0"

project: legal-rag
experiment: legal_rag

defaults:
  base_dir: /data/workspace/${USER}

  # Dataset configuration
  dataset: artefactory/Argimi-Legal-French-Jurisprudence
  subset: constit
  split: train
  doc_id_column: id
  title_column: title

  # Model configuration
  encoder_model: maastrichtlawtech/colbert-legal-french

  # Index configuration
  index_name: colbert_legal_french_${subset}_index

  # Query configuration
  k: 100
  query_batch_size: 32

  # Paths
  index_dir: ${base_dir}/legal-rag/index
  questions_dir: ${base_dir}/legal-rag/questions/${subset}
  output_dir: ${base_dir}/legal-rag/evaluation/colbert_legal_french

steps:
  # Step 0: Batch query the index
  - command: "python scripts/batch_query.py"
    arguments:
      questions: "${questions_dir}"
      output: "${output_dir}"
      path: "${index_dir}"
      index.name: "${index_name}"
      encoder: "${encoder_model}"
      source.name: "${dataset}"
      subset: "${subset}"
      split: "${split}"
      doc_id_column: "${doc_id_column}"
      title_column: "${title_column}"
      k: ${k}
      batch_size: ${query_batch_size}
    gpu_count: 1
    artifacts:
      inputs:
        - path: "${index_dir}/${index_name}"
          type: Dataset
        - path: "${questions_dir}"
          type: Dataset
      outputs:
        - path: "${output_dir}/run.txt"
          type: Dataset
        - path: "${output_dir}/qrels.txt"
          type: Dataset

  # Step 1: Evaluate with pyserini
  - command: "python -m pyserini.eval.trec_eval -c -m recall.1,5,10,100 ${output_dir}/qrels.txt ${output_dir}/run.txt"
    artifacts:
      inputs:
        - path: "${output_dir}/run.txt"
          type: Dataset
        - path: "${output_dir}/qrels.txt"
          type: Dataset
      outputs:
        - path: "${output_dir}/metrics.txt"
          type: Metrics
