{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7010a4",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "# French Legal Agent Demo\n",
    "\n",
    "Colab-ready notebook (py:percent via Jupytext) for running the French Legal RAG\n",
    "agent. It wires the DSPy agent, and lets you ask one or many questions. The LM can\n",
    "run via Hugging Face Serverless Inference (with `HF_TOKEN`) or a local\n",
    "OpenAI-compatible server (provide `GENERATOR_API_BASE`). DSPy (via LiteLLM)\n",
    "auto-switches providers based on whether an API base is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059d594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "from etils import epath\n",
    "\n",
    "\"\"\"Detect Colab early; avoid hard imports elsewhere.\"\"\"\n",
    "try:\n",
    "    import google.colab  # noqa: ignore\n",
    "\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f32d89",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Configuration (Colab form)\n",
    "\n",
    "All editable constants live here. Colab renders `@param` comments as form fields.\n",
    "Tokens can come from login (`interpreter_login`) or manual entry; other fields use\n",
    "these form values. Set `GENERATOR_API_KEY` to your own HF token, or point\n",
    "`GENERATOR_API_BASE` to your OpenAI-compatible server to bypass HF serverless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATOR_API_KEY = \"\"  # @param {type:\"string\"}\n",
    "GENERATOR_API_BASE = \"\"  # @param {type:\"string\"}\n",
    "GENERATOR_MODEL_ID = (\n",
    "    \"mistralai/Mistral-Small-3.1-24B-Instruct-2503\"  # @param {type:\"string\"}\n",
    ")\n",
    "ENCODER_MODEL_ID = \"maastrichtlawtech/colbert-legal-french\"  # @param {type:\"string\"}\n",
    "SEARCH_K = 5  # @param {type:\"integer\"}\n",
    "MAX_NEW_TOKENS = 512  # @param {type:\"integer\"}\n",
    "TEMPERATURE = 0.2  # @param {type:\"number\"}\n",
    "MAX_ITERS = 4  # @param {type:\"integer\"}\n",
    "INSTRUCTIONS = \"First call search_legal_docs to find candidate ids and previews. Then call lookup_legal_doc on specific ids you want to read in full. Ground your answer in the retrieved text and cite the document ids you used.\"  # @param {type:\"string\"}\n",
    "configured_index = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14ad8c",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Repo setup\n",
    "\n",
    "When opened directly from GitHub, this notebook installs the full repo so that\n",
    "`agent.py` and utilities are importable. If the package is already installed,\n",
    "the cell is a no-op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0895e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_URL = \"https://github.com/artefactory-argimi/legal_rag.git\"  # change if you fork\n",
    "\n",
    "try:\n",
    "    import legal_rag as _  # noqa: F401\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "\n",
    "    subprocess.run(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"--quiet\",\n",
    "            \"--upgrade\",\n",
    "            f\"git+{REPO_URL}\",\n",
    "        ],\n",
    "        check=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c478a1",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Hugging Face login (Serverless Inference)\n",
    "\n",
    "If running in Colab and using the Hugging Face provider without an `HF_TOKEN`\n",
    "set, prompt for a token using `huggingface_hub.interpreter_login()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd291063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import get_token, interpreter_login\n",
    "\n",
    "if not GENERATOR_API_BASE and not GENERATOR_API_KEY:\n",
    "    # Default to HF serverless; prompt for token once if none was supplied.\n",
    "    interpreter_login()\n",
    "    GENERATOR_API_KEY = get_token() or \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65333e5",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Index loading\n",
    "You must upload a zipped archive of the index (e.g. `legal_rag_index.zip`) each\n",
    "run; the upload flow will unpack it under `/content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IN_COLAB:\n",
    "    raise FileNotFoundError(\n",
    "        \"Index upload is only supported in Colab. Build/run locally with an existing index.\"\n",
    "    )\n",
    "\n",
    "from google.colab import files  # type: ignore\n",
    "\n",
    "uploaded = files.upload()\n",
    "if not uploaded:\n",
    "    raise FileNotFoundError(\"No index uploaded.\")\n",
    "# Pick the first uploaded file.\n",
    "fn, data = next(iter(uploaded.items()))\n",
    "local_path = f\"/content/{fn}\"\n",
    "print(f'User uploaded file \"{fn}\" with length {len(data)} bytes')\n",
    "\n",
    "archive = epath.Path(local_path)\n",
    "if not archive.name.lower().endswith(\".zip\"):\n",
    "    raise ValueError(f\"Uploaded file is not a zip archive: {archive}\")\n",
    "\n",
    "content_root = epath.Path(\"/content\")\n",
    "with zipfile.ZipFile(archive, \"r\") as zf:\n",
    "    zf.extractall(str(content_root))\n",
    "\n",
    "# The archive built by scripts/indexer.py should contain an `index/` directory.\n",
    "candidate = content_root / \"index\"\n",
    "if not candidate.exists():\n",
    "    # Fall back to a directory matching the archive stem, or a single extracted dir.\n",
    "    stem_dir = content_root / archive.stem\n",
    "    if stem_dir.exists():\n",
    "        candidate = stem_dir\n",
    "    else:\n",
    "        dirs = [p for p in content_root.iterdir() if p.is_dir()]\n",
    "        if len(dirs) == 1:\n",
    "            candidate = dirs[0]\n",
    "\n",
    "if not candidate.exists():\n",
    "    raise FileNotFoundError(\"Archive extracted but index folder not found.\")\n",
    "\n",
    "configured_index = candidate\n",
    "print(f\"✓ Index extracted to {configured_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f5622",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Agent configuration\n",
    "We build the DSPy ReAct agent using the helpers in `agent.py`.\n",
    "\n",
    "- Encoder: local, GPU if available (`torch.cuda.is_available()`), no API keys.\n",
    "- Generator: defaults to Hugging Face Serverless (`huggingface/<model>` with token from\n",
    "  `interpreter_login`) and falls back to a local OpenAI-compatible server when\n",
    "  `GENERATOR_API_BASE` is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from legal_rag.agent import build_agent\n",
    "\n",
    "generator_api_key = GENERATOR_API_KEY or None\n",
    "# If no API base is set, default to HF Serverless and try to pick up a saved token.\n",
    "if not GENERATOR_API_BASE and not generator_api_key:\n",
    "    generator_api_key = get_token()\n",
    "generator_api_base = GENERATOR_API_BASE or None\n",
    "\n",
    "agent = build_agent(\n",
    "    student_model=GENERATOR_MODEL_ID,\n",
    "    encoder_model=ENCODER_MODEL_ID,\n",
    "    generator_api_key=generator_api_key,\n",
    "    generator_api_base=generator_api_base,\n",
    "    index_folder=configured_index,  # used by ColBERT retriever in agent.py\n",
    "    search_k=SEARCH_K,\n",
    "    max_new_tokens=MAX_NEW_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    "    instructions=INSTRUCTIONS,\n",
    "    max_iters=MAX_ITERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52e4f8",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "## Ask questions\n",
    "Provide a single question as a string or multiple questions as an iterable.\n",
    "The agent will search the index, optionally call lookup, and return grounded\n",
    "answers. Adjust `queries` below and re-run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries: Iterable[str] | str = [\n",
    "    \"Quelles sont les obligations principales de l'employeur en matière de sécurité au travail ?\",\n",
    "    \"Dans quel cas un contrat peut-il être résilié pour imprévision selon le droit français ?\",\n",
    "]\n",
    "\n",
    "if isinstance(queries, str):\n",
    "    questions = [queries]\n",
    "else:\n",
    "    questions = list(queries)\n",
    "\n",
    "for idx, question in enumerate(questions, start=1):\n",
    "    print(f\"\\n=== Question {idx} ===\")\n",
    "    print(question)\n",
    "    prediction = agent(question=question)\n",
    "    print(\"\\n--- Réponse ---\")\n",
    "    print(prediction.answer)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\"",
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
